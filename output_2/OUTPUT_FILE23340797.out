cuda
{'dataset_params': {'im_path': 'data/train/images'}, 'diffusion_params': {'num_timesteps': 1000, 'beta_start': 0.0001, 'beta_end': 0.02}, 'model_params': {'im_channels': 3, 'im_size': 32, 'down_channels': [32, 64, 128, 256], 'mid_channels': [256, 256, 128], 'down_sample': [True, True, False], 'time_emb_dim': 128, 'num_down_layers': 2, 'num_mid_layers': 2, 'num_up_layers': 2, 'num_heads': 4}, 'train_params': {'task_name': 'default_fid', 'batch_size': 128, 'num_epochs': 30, 'num_samples': 100, 'num_grid_rows': 10, 'lr': 0.0002, 'ckpt_name': 'ddpm_ckpt_cifar2.pth'}}
Files already downloaded and verified
Files already downloaded and verified
<torch.utils.data.dataloader.DataLoader object at 0x7f82487040a0>
Tensor shape: torch.Size([128, 3, 32, 32])
{'dataset_params': {'im_path': 'data/train/images'}, 'diffusion_params': {'num_timesteps': 1000, 'beta_start': 0.0001, 'beta_end': 0.02}, 'model_params': {'im_channels': 3, 'im_size': 32, 'down_channels': [32, 64, 128, 256], 'mid_channels': [256, 256, 128], 'down_sample': [True, True, False], 'time_emb_dim': 128, 'num_down_layers': 2, 'num_mid_layers': 2, 'num_up_layers': 2, 'num_heads': 4}, 'train_params': {'task_name': 'default_fid', 'batch_size': 128, 'num_epochs': 30, 'num_samples': 100, 'num_grid_rows': 10, 'lr': 0.0002, 'ckpt_name': 'ddpm_ckpt_cifar2.pth'}}

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 23340797: <testjob_ddpm_cifar2> in cluster <dcc> Exited

Job <testjob_ddpm_cifar2> was submitted from host <gbarlogin1> by user <s233670> in cluster <dcc> at Wed Dec  4 12:45:51 2024
Job was executed on host(s) <4*n-62-20-2>, in queue <gpuv100>, as user <s233670> in cluster <dcc> at Wed Dec  4 12:53:32 2024
</zhome/d8/f/203934> was used as the home directory.
</zhome/d8/f/203934/ddpm/deep_learning_ddpm_group_7> was used as the working directory.
Started at Wed Dec  4 12:53:32 2024
Terminated at Wed Dec  4 12:53:50 2024
Results reported at Wed Dec  4 12:53:50 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
### ------------- specify queue name ---------------- 
#BSUB -q gpuv100

### ------------- specify gpu request---------------- 
#BSUB -gpu "num=1:mode=exclusive_process"

### ------------- specify job name ---------------- 
#BSUB -J testjob_ddpm_cifar2

### ------------- specify number of cores ---------------- 
#BSUB -n 4 
#BSUB -R "span[hosts=1]"

### ------------- specify CPU memory requirements ---------------- 
#BSUB -R "rusage[mem=30GB]"

#BSUB -W 12:00 
#BSUB -o output_2/OUTPUT_FILE%J.out 
#BSUB -e output_2/OUTPUT_FILE%J.err

source "/zhome/d8/f/203934/ddpm/deep_learning_ddpm_group_7/.venv/bin/activate"
python -m tools.train_ddpm
python -m tools.sample_ddpm
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   18.00 sec.
    Max Memory :                                 71 MB
    Average Memory :                             71.00 MB
    Total Requested Memory :                     122880.00 MB
    Delta Memory :                               122809.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                7
    Run time :                                   19 sec.
    Turnaround time :                            479 sec.

The output (if any) is above this job summary.



PS:

Read file <output_2/OUTPUT_FILE23340797.err> for stderr output of this job.

